{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUM 2023-24 Twierdzenie Bayesa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wzór Bayesa\n",
    "<a id='wzor_bayesa'></a>\n",
    "\n",
    "$$p(\\theta\\mid x) = \\dfrac{p(x\\mid \\theta)\\cdot p(\\theta)}{p(x)}$$\n",
    "\n",
    "* Jeśli $\\theta$ może przyjmować tylko skończenie wiele wartości, tzn. $\\theta\\in\\{\\theta^1, \\ldots, \\theta^T\\}$, to możemy zapisać\n",
    "$$\\begin{align}\n",
    "p(x) &= p(x, \\theta = \\Theta) = p(x, \\theta=\\Theta^1) + \\ldots + p(x, \\theta=\\Theta^T)\\\\\n",
    "&= p(x\\mid\\theta=\\Theta^1)p(\\theta=\\Theta^1) + \\ldots + p(x\\mid\\theta=\\Theta^T)p(\\theta=\\Theta^T)\n",
    "\\end{align}$$\n",
    "i wstawić to do powyższego wzoru (po co? tak będzie wygodniej, o czym przekonamy się za chwilę):\n",
    "\n",
    "$$\\begin{align}\n",
    "p(\\theta\\mid x)&=\\dfrac{p(x\\mid \\theta)\\cdot p(\\theta)}{p(x\\mid\\theta=\\Theta^1)p(\\theta=\\Theta^1) + \\ldots + p(x\\mid\\theta=\\Theta^T)p(\\theta=\\Theta^T)}\\\\\n",
    "&= \\dfrac{p(x\\mid \\theta)\\cdot p(\\theta)}{\\sum_{k}p(x\\mid\\theta=\\Theta^k)p(\\theta=\\Theta^k)}\n",
    "\\end{align}$$\n",
    "\n",
    "* Sam wzór Bayesa wynika wprost z definicji, więc jest dość prosty. Znacznie ciekawsze będzie to, w jaki sposób go użyjemy.\n",
    "\n",
    "### Wzór Bayesa pisany poprawnie\n",
    "* Po dwóch stronach równości mamy dwie funkcje dwóch parametrów: $x$ oraz $\\theta$.\n",
    "  * Jeśli chcemy mieć równość liczb, a nie funkcji, to powinniśmy wybrać jakąś wartość $x$ - niech to będzie np. $x^1$ - oraz wartość $\\theta$ - powiedzmy $\\Theta^t$ dla pewnego $t\\in\\{1, \\ldots, T\\}$ - i napisać\n",
    "$$p(\\theta = \\theta^t\\mid x = x^1) = \\dfrac{p(x = x^1\\mid\\theta=\\Theta^t)\\cdot p(\\theta=\\Theta^t)}{p(x=x^1)}$$\n",
    "  * Oczywiście równość zachodzi dla każdej pary dowolnie wybranych wartości $x$ oraz $\\theta$.\n",
    "\n",
    "---\n",
    "### Wzór Bayesa - więcej zmiennych\n",
    "* Zamiast $x$ i $\\theta$ oczywiście możemy wstawić do wzoru Bayesa więcej zmiennych. Zasada jest podobna, np.\n",
    "$$p(\\theta,\\alpha\\mid x,y,z) = \\dfrac{p(x,y,z\\mid \\theta,\\alpha)\\cdot p(\\theta,\\alpha)}{p(x,y,z)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uczenie maszynowe\n",
    "\n",
    "* Przy założeniu [**I.I.D.**](./stat_03_zmienne_niezalezne.ipynb) wiedza o wartościach elementów ze zbioru treningowego nie ma prawa zmieniać naszej wiedzy na temat wartości ze zbioru testowego.\n",
    "  * Czy to oznacza, że teoria jest niepoprawna, skoro modele się uczą?\n",
    "* Teoria jest poprawna.\n",
    "  * Powyższe stwierdzenie jest prawdziwe tylko wtedy, kiedy znamy rozkład $p(x)$.\n",
    "  * Wtedy w oczywisty sposób samplowanie z tego rozkładu nie może zwiększać wiedzy na jego temat, ani też na temat przyszłych próbek\n",
    "  * Natomiast dopóki nie znamy $p(x)$, samplowanie z tego rozkładu zwiększa naszą wiedzę na jego temat i w ten sposób, pośrednio, wiedzę o przyszłych samplach.\n",
    "* Rozkład prawdopodobieństwa $p(x)$ mówi o niepewności konkretnej wartości wylosowanej z $x$.\n",
    "  * jak formalnie zapisać naszą niepewność co do rozkładu $p$?\n",
    "  * Czy to wymaga wprowadzenia nowej meta-teorii, która ma opisywać tę teorię?\n",
    "  * Na szczęście nie.\n",
    "* założenie IID nie zawsze jest spełnione\n",
    "  * w niektórych typach uczenia (problemach) mamy do czynienia z rozkładami danych, które **zmieniają** się"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametr $\\theta$\n",
    "\n",
    "* Wprowadzamy rozkład łączny $p(x,\\theta)$.\n",
    "  * Musimy go zdefiniować sami, nie korzystając z żadnych danych treningowych.\n",
    "  * Pomysł polega na tym, że różne ustalone wartości $\\Theta$ oznaczają nasze różne hipotezy o __rozkładzie__ $p(x)$. \n",
    "  * Formalnie, np. hipoteza $\\theta = \\Theta^1$ oznacza __warunkowy__ rozkład prawdopodobieństwa $$p(x\\mid \\theta=\\Theta^1)$$\n",
    "\n",
    "a nasz obecny stopień przekonania co do poprawności hipotezy $\\theta = \\Theta^1$ dany jest jako rozkład __brzegowy__\n",
    "$$p(\\theta=\\Theta^1)$$\n",
    "  * Nie \"wybieramy\" żadnej hipotezy, żeby powiedzieć coś o $x$ - używamy wszystkich hipotez jednocześnie, ważąc je prawdopodobieństwem $p(\\theta)$.\n",
    "  * Nasza obecna wiedza o $x$ to po prostu drugi rozkład __brzegowy__\n",
    "$$p(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jak zdefiniować $p(x,\\theta)$ bez danych treningowych\n",
    "\n",
    "* musimy zadbać, żeby uwzględnić w tym rozkładzie wszystkie możliwe hipotezy.\n",
    "  * jeśli modelujemy rzut niesymetryczną monetą, to $x$ może przyjąć jedną z dwóch wartości: orzeł lub reszka.\n",
    "  * Natomiast $\\theta$ musi przyjmować nieskończenie wiele wartości z przedziału $[0,1]$, jeśli zinterpretujemy $\\theta=T$ jako \"prawdopodobieństwo wypadnięcia orła wynosi $T$\".\n",
    "* Czyli np. definiujemy $p(x=\\mathrm{orzeł}\\mid\\theta=T) = T$ oraz $p(x=\\mathrm{reszka}\\mid\\theta=T) = 1-T$.\n",
    "* Brakuje jeszcze $p(\\theta)$ i tu pojawia się problem.\n",
    "  * Nie ma żadnego \"dobrego\" rozkładu na $\\theta$,\n",
    "    * musimy po prostu wybrać cokolwiek.\n",
    "  * Ten rozkład będzie się zmieniał podczas uczenia (o tym za chwilę)\n",
    "    * w granicy nieskończenie wielu obserwacji wskaże nam \"najprawdziwszą\" hipotezę\n",
    "    * jego wartość początkową trzeba \"zgadnąć\".\n",
    "* Zły rozkład $p(\\theta)$ może bardzo spowolnić uczenie\n",
    "  * jeśli jesteśmy bardzo przekonani do niepoprawnej hipotezy, to musimy obejrzeć bardzo dużo przykładów, żeby w końcu zmienić zdanie.\n",
    "* Wracając do pierwszego punktu\n",
    "  * załóżmy, że w rozkładzie $p(x,\\theta)$ **nie** uwzględnimy wszystkich możliwych hipotez,\n",
    "    * nawet przy \"nieskończenie wielu obserwacjach\" możemy mieć niekompletną wiedzę o $x$.\n",
    "  * niech początku pewne wartości $\\theta$ będą miały prawdopodobieństwo zero\n",
    "    * jeśli $p(\\theta=T)=0$, to jesteśmy pewni, że $\\theta\\neq T$ i żadna liczba obserwacji $x$ nie przekona nas do $\\theta=T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie Bayesowskie — znowu założenie I.I.D.\n",
    "\n",
    "* Założenie I.I.D. obowiązuje tylko przy ustalonej hipotezie, to znaczy przy ustalonej wartości $\\theta$.\n",
    "  * Czyli dla dowolnej wartości $\\Theta^k$\n",
    "$$p(x_1=x^1, \\ldots, x_N=x^N\\mid\\theta=\\Theta^k) = p(x=x^1\\mid\\theta=\\Theta^k)\\ldots p(x=x^N\\mid\\theta=\\Theta^k)$$\n",
    "  * Chcemy w ten sposób powiedzieć: \"nie wiemy, która hipoteza najlepiej opisuje $x$, ale każda z tych hipotez spełnia wg nas założenie I.I.D.\".\n",
    "  * Kluczowe jest to, że teraz\n",
    "$$p(x_1=x^1, \\ldots, x_N=x^N) \\neq p(x=x^1)\\ldots p(x=x^N)$$\n",
    "  czyli być może uda się wnioskować o kolejnych samplach na podstawie poprzednich.\n",
    "* Niech $D_{Tr}$ oznacza nasz zbiór treningowy ($D$ jak _dataset_) o rozmiarze $N$.\n",
    "  $$D_{Tr}=\\{x_1=x^1, x_2=x^2 \\ldots, x_N=x^N\\}$$\n",
    "* Chcemy teraz wnioskować o $x_{N+1}$ na podstawie $D_{Tr}$.\n",
    "  * Załóżmy na chwilę, że $\\theta$ może przyjmować tylko skończenie wiele wartości ze zbioru $\\{\\Theta^1, \\ldots, \\Theta^K\\}$.\n",
    "  * To bardzo niepoprawne założenie, ale dzięki temu zobaczymy wzór ze skończoną sumą.\n",
    "  * W ogólnym przypadku, jeśli mamy szczęście, zamiast sumy jest bardzo skomplikowana całka."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Predictive Distribution (PPD)\n",
    "\n",
    "$$\\begin{align}\n",
    "p(x_{N+1}\\mid D_{Tr}) &= p(x_{N+1}\\mid\\theta=\\Theta^1)p(\\theta=\\Theta^1\\mid D_{Tr}) + \\ldots + p(x_{N+1}\\mid\\theta=\\Theta^K)p(\\theta=\\Theta^K\\mid D_{Tr})\\\\\n",
    "&= \\sum_{k=1}^K p(x_{N+1}\\mid\\theta=\\Theta^k)p(\\theta=\\Theta^k\\mid D_{Tr})\n",
    "\\end{align}$$\n",
    "* Rozbijamy $\\theta$ na wszystkie możliwe przypadki.\n",
    "  *  Wiedza o $x_{N+1}$ to średnia wiedza po wszystkich możliwych hipotezach. Ale używamy tu \"zmienionego\" rozkładu brzegowego $p(\\theta)$, ponieważ warunkujemy go zbiorem treningowym!\n",
    "  *  Jak policzyć $p(\\theta=\\theta^k\\mid D_{Tr})$? Użyjmy wzoru Bayesa.\n",
    "$$p(\\theta=\\Theta^k\\mid D_{Tr}) = \\dfrac{p(D_{Tr}\\mid\\theta=\\Theta^k)p(\\theta=\\Theta^k)}{p(D_{Tr})}$$\n",
    "\n",
    "<img style=\"float: left;\" src=\"ml_figures/bayesian-concept.png\" width=300> \n",
    "\n",
    "* Zamieniliśmy jedno $p$ na trzy różne — czy to pomogło?\n",
    "  * Przypomnijmy, że mamy zdefiniowany rozkład $p(x,\\theta)$.\n",
    "  * W praktyce możemy założyć, że łatwo policzyć $p(\\theta)$ oraz $p(x\\mid\\theta)$ dla dowolnej wartości $\\Theta$\n",
    "    * z reguły tak się właśnie definiuje ten rozkład łączny — poprzez każdą hipotezę z osobna oraz rozkład na hipotezach).\n",
    "      \n",
    "  * Pokażmy, jak policzyć wyrazy występujące w ułamku:\n",
    "  1. $p(D_{Tr}\\mid\\theta=\\Theta^k)$ to prawdopodobieństwo zbioru treningowego w hipotezie $\\theta=\\Theta^k$:\n",
    "$$p(D_{Tr}\\mid\\theta=\\Theta^k) = p(x=x^1\\mid\\theta=\\Theta^k)\\ldots p(x=x^N\\mid\\theta=\\Theta^k)$$\n",
    "    * uwaga — tu korzystamy z założenia I.I.D.)\n",
    "      \n",
    "  2. $p(\\theta=\\Theta^k)$ odczytujemy po prostu z rozkładu brzegowego $p(\\theta)$\n",
    "  3. $p(D_{Tr})$ trzeba rozpisać (właśnie dlatego na początku tego notebooka [wzór Bayesa](#wzor_bayesa) rozpisywaliśmy mianownik):\n",
    "$$p(D_{Tr}) = p(D_{Tr}\\mid\\theta=\\Theta^1)p(\\theta=\\Theta^1) + \\ldots + p(D_{Tr}\\mid\\theta=\\Theta^K)p(\\theta=\\Theta^K)$$\n",
    "ale to już umiemy policzyć, patrz punkty 1. i 2.\n",
    "\n",
    "* To jest pełna odpowiedź na pytanie: _zbiór treningowy nie daje nam żadnej nowej wiedzy na temat punktów ze zbioru testowego. Ale przecież to stoi w sprzeczności z faktem, że modele się uczą. Jak to wytłumaczyć?_\n",
    "  * Zaobserwowany zbiór treningowy niejako zmienia rozkład brzegowy $p(\\theta)$\n",
    "  * tak naprawdę ten rozkład nie może się zmienić, ale wzory _wyglądają_ tak, jak gdyby został on uwarunkowany zbiorem treningowym\n",
    "  * ten \"zmieniony\" rozkład służy do ważonego uśrednienia wszystkich hipotez o $x_{N+1}$.\n",
    "* Zamiast $x_{N+1}$ możemy wstawić dowolnie wiele kolejnych losowań, np. cały zbiór testowy.\n",
    "* __posterior predictive distribution__ to prawdopodobny rozkład wszystkich niezaobserwowanych wartości uwarunkowany wartościami obserwowanymi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior, likelihood, posterior\n",
    "$$p(\\theta=\\Theta^k\\mid D_{Tr}) = \\dfrac{p(D_{Tr}\\mid \\theta=\\Theta^k)\\cdot p(\\theta=\\Theta^k)}{\\sum_{k}p(D_{Tr}\\mid\\theta=\\Theta^k)p(\\theta=\\Theta^k)}$$\n",
    "\n",
    "<img style=\"float: right;\" src=\"ml_figures/bayesian-concept.png\" width=300> \n",
    "\n",
    "* $p(\\theta=\\Theta^k)$ w liczniku wzoru Bayesa to __prior__ albo __wiedza a priori__, czyli wszystko to, co wiemy o wartościach $\\theta$ bez patrzenia na zbiór treningowy $D_{Tr}$,\n",
    "* $p(D_{Tr}\\mid\\theta=\\Theta^k)$ w liczniku to __likelihood__, który mówi nam, jak bardzo prawdopodobny byłby dataset $D_{Tr}$, gdyby $\\Theta^k$ było prawdziwą hipotezą,\n",
    "* $p(\\theta=\\Theta^k\\mid D_{Tr})$ po lewej stronie równości to __posterior__ albo __wiedza a posteriori__, czyli wszystko to, co wiemy o wartościach $\\theta$ po obejrzeniu zbioru treningowego $D_{Tr}$.\n",
    "* $\\sum_{k}p(D_{Tr}\\mid\\theta=\\Theta^k)p(\\theta=\\Theta^k)$ to **evidence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoria a praktyka\n",
    "\n",
    "$$p(x_{N+1}\\mid D_{Tr}) = \\sum_{k=1}^K p(x_{N+1}\\mid\\theta=\\Theta^k)p(\\theta=\\Theta^k\\mid D_{Tr})$$\n",
    "opisuje wszystko, czego możemy się nauczyć. Nie da się wyciągnąć z $D_{Tr}$ jeszcze więcej wiedzy o $x_{N+1}$.\n",
    "\n",
    "* Ale\n",
    "  * Nie da się uwzględnić wszystkich hipotez w $p(x,\\theta)$.\n",
    "    * Już w wypadku rzutu monetą obliczenia są skomplikowane, a to przecież jest najprostszy z możliwych przykładów i daleko mu do problemów, które stawiamy przed sieciami neuronowymi.\n",
    "  * Nie da się sensownie przeliczyć PPD, może za wyjątkiem bardzo specyficznych rozkładów $p(\\theta,x)$.\n",
    "\n",
    "* Machine Learning to sztuka znalezienia dobrego i szybkiego przybliżenia powyższego wzoru.\n",
    "  * Poniżej dwa najpopularniejsze podejścia.\n",
    "  * Niestety, oba zakładają \"wybór\" jednej z hipotez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum a Posteriori (MAP)\n",
    "\n",
    "* Szukamy takiego $\\widehat\\theta$, które zmaksymalizuje wartość liczbową posteriora:\n",
    "$$\\widehat\\theta = \\operatorname{arg}\\max_{\\theta^k} p(\\theta=\\Theta^k\\mid D_{Tr})$$\n",
    "  * a następnie \"wybieramy\" to jedno $\\widehat\\theta$ i tylko na jego podstawie dokonujemy predykcji:\n",
    "$$p(x_{N+1}\\mid D_{Tr}) \\cong p(x_{N+1}\\mid\\theta=\\widehat\\Theta)$$\n",
    "  * innymi słowy liczymy na to, że:\n",
    "$$p(\\theta=\\widehat\\theta\\mid D_{Tr})\\simeq1$$\n",
    "i wtedy\n",
    "$$\\sum_{k=1}^K p(x_{N+1}\\mid\\theta=\\Theta^k)p(\\theta=\\Theta^k\\mid D_{Tr}) \\cong p(x_{N+1}\\mid\\theta=\\widehat\\Theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood Estimator (MLE)\n",
    "\n",
    "Szukamy takiego $\\theta^k$, które zmaksymalizuje wartość liczbową likelihoodu:\n",
    "\n",
    "$$\\widehat\\theta = \\underset{\\Theta^k}{\\arg\\max}\\;p\\,(D_{Tr}\\mid\\theta=\\Theta^k)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting,\n",
    "\n",
    "* sytuacja, w której model zapamiętuje zbiór treningowy, ale nie umie potem wykorzystać tej wiedzy do predykcji na zbiorze testowym.\n",
    "  * to cena, jaką płacimy za zastąpienie PPD przez MLE. \n",
    "  * overfitting __nie występuje__ w przypadku PPD - to jest wzór dokładny, więc nic się nie może \"zepsuć\".\n",
    "  * to zjawisko charakterystyczne właśnie dla MLE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
